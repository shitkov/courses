{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Mun7SyNQV7TA"
      ]
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:18:43.325903Z",
          "start_time": "2021-04-17T09:18:43.321914Z"
        },
        "id": "SOtW61Z_V7Se"
      },
      "source": [
        " # Тренировка нейронных сетей на реальных данных\n",
        "\n",
        "## Классификация котов и собак"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E65Y8aDV7Sn"
      },
      "source": [
        "# Запускать только если вы работаете в google collab\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:03.502176Z",
          "start_time": "2021-04-17T09:31:03.452308Z"
        },
        "id": "X_ZdW4DkV7Sq"
      },
      "source": [
        "# !wget -nc https://www.dropbox.com/s/gqdo90vhli893e0/data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -n data.zip -d /content/drive/MyDrive/hw_01"
      ],
      "metadata": {
        "id": "IkNr1WRHo7sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:00.652880Z",
          "start_time": "2021-04-17T09:31:00.646898Z"
        },
        "id": "osMdnRWkV7So"
      },
      "source": [
        "import os\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "# from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBBvKt2vV7Sp"
      },
      "source": [
        "Определим в одном месте все константы, которые понадобятся нам в дальнейшем. Их смысл будет прояснён по мере использования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:01.256152Z",
          "start_time": "2021-04-17T09:31:01.251140Z"
        },
        "id": "FwlhcyxNV7Sp"
      },
      "source": [
        "### Let's have a cell with global hyperparameters for the CNNs in this notebook\n",
        "\n",
        "# Path to a directory with image dataset and subfolders for training, validation and final testing\n",
        "DATA_PATH = '/content/drive/MyDrive/hw_01/' # PATH TO THE DATASET\n",
        "\n",
        "# Number of threads for data loader\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "# Image size: even though image sizes are bigger than 96, we use this to speed up training\n",
        "SIZE_H = SIZE_W = 96\n",
        "N_CHANNELS = 3\n",
        "\n",
        "# Number of classes in the dataset\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# Epochs: number of passes over the training data, we use it this small to reduce training babysitting time\n",
        "EPOCH_NUM = 30\n",
        "\n",
        "# Batch size: for batch gradient descent optimization, usually selected as 2**K elements\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Images mean and std channelwise\n",
        "image_mean = [0.485, 0.456, 0.406]\n",
        "image_std  = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Last layer (embeddings) size for CNN models\n",
        "EMBEDDING_SIZE = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:02.357576Z",
          "start_time": "2021-04-17T09:31:02.261833Z"
        },
        "id": "SToZnTvaV7Sq"
      },
      "source": [
        "# используем GPU при наличии\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:09.352658Z",
          "start_time": "2021-04-17T09:31:09.348670Z"
        },
        "id": "2phj2vOnV7Sr"
      },
      "source": [
        "transformer = transforms.Compose([\n",
        "    transforms.Resize((SIZE_H, SIZE_W)),        # scaling images to fixed size\n",
        "    transforms.ToTensor(),                      # converting to tensors\n",
        "    transforms.Normalize(image_mean, image_std) # normalize image data per-channel\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:09.818701Z",
          "start_time": "2021-04-17T09:31:09.799750Z"
        },
        "id": "4oLkBZKcV7Sr"
      },
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(os.path.join(DATA_PATH, 'train_11k'), transform=transformer)\n",
        "val_dataset   = torchvision.datasets.ImageFolder(os.path.join(DATA_PATH, 'val'), transform=transformer)\n",
        "test_dataset  = torchvision.datasets.ImageFolder(os.path.join(DATA_PATH, 'test_labeled'), transform=transformer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:10.245710Z",
          "start_time": "2021-04-17T09:31:10.232737Z"
        },
        "id": "QKpOvEZgV7Ss"
      },
      "source": [
        "n_train, n_val, n_test = len(train_dataset), len(val_dataset), len(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train, n_val, n_test"
      ],
      "metadata": {
        "id": "PFIIyuXIt6cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGGKnqzIV7Ss"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gLXaDjBV7St"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51tm4l4pV7St"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:31:22.137667Z",
          "start_time": "2021-04-17T09:31:22.133648Z"
        },
        "id": "QG3EkVwBV7St"
      },
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:32:06.060430Z",
          "start_time": "2021-04-17T09:32:06.051427Z"
        },
        "id": "xEBZGPXlV7Su"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, val_loader, loss_fn, opt, n_epochs):\n",
        "    '''\n",
        "    model: нейросеть для обучения,\n",
        "    train_loader, val_loader: загрузчики данных\n",
        "    loss_fn: целевая метрика (которую будем оптимизировать)\n",
        "    opt: оптимизатор (обновляет веса нейросети)\n",
        "    n_epochs: кол-во эпох, полных проходов датасета\n",
        "    '''\n",
        "    train_loss = []\n",
        "    val_accuracy = []\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        model.train(True) # enable dropout / batch_norm training behavior\n",
        "        for X_batch, y_batch in tqdm(train_loader):\n",
        "            # move data to target device\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            # train on batch: compute loss, calc grads, perform optimizer step and zero the grads\n",
        "            opt.zero_grad()\n",
        "            predictions = model(X_batch)\n",
        "            loss = loss_fn(predictions, y_batch)\n",
        "            loss.backward()\n",
        "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "            opt.step()\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        model.train(False) # disable dropout / use averages for batch_norm\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            # move data to target device\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            # compute logits\n",
        "            logits = model(X_batch)\n",
        "            y_pred = logits.max(1)[1].data\n",
        "            val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "        # print the results for this epoch:\n",
        "        print(f'Epoch {epoch + 1} of {n_epochs} took {time.time() - start_time:.3f}s')\n",
        "\n",
        "        train_loss_value = np.mean(train_loss[-n_train // BATCH_SIZE :])\n",
        "        val_accuracy_value = np.mean(val_accuracy[-n_val // BATCH_SIZE :]) * 100\n",
        "        \n",
        "        print(f\"  training loss (in-iteration): \\t{train_loss_value:.6f}\")\n",
        "        print(f\"  validation accuracy: \\t\\t\\t{val_accuracy_value:.2f} %\")\n",
        "\n",
        "    return train_loss, val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhQT91OLV7Su"
      },
      "source": [
        "## Задание 1. Реализовать сверточную нейросеть для классификации котов и собак (0.4 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdTmtSFnV7Sv"
      },
      "source": [
        "### First step\n",
        "\n",
        "**conv-pool-conv-pool-dense-dense!**\n",
        "\n",
        "Создайте мини-сверточную нейронную сеть со следующей структурой:\n",
        "* Входной слой\n",
        "* 3 классических сверточных блока`convolution->relu->pool`: \n",
        "  * свертка 3x3 с 128 фильтрами и функцией активации _ReLU_\n",
        "  * 2x2 пулинг (или поставьте для предыдущей свертки страйд = 3)\n",
        "* Flatten\n",
        "* 30% Dropout \n",
        "* Линейный слой с 256 нейронами и функцией активации _ReLU_\n",
        "* 30% dropout\n",
        "* Выходной линейный слой.\n",
        "\n",
        "__Convolutional layers__ в торче создаются как любой другой слой, но у него есть особые параметры:\n",
        "\n",
        "__`...`__\n",
        "\n",
        "__`model.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3)) # светрка`__\n",
        "\n",
        "__`model.add_module('pool1', nn.MaxPool2d(2)) # max pooling 2 на 2`__\n",
        "\n",
        "__`...`__\n",
        "\n",
        "\n",
        "Когда вы закончите создание нейросети (когда функция compute_loss не будет поднимать ошибки), обучите её с оптимайзером __Adam__ с LR = 3e-4 (Константа Карпатого)\n",
        "\n",
        "Если всё верно, вы должны получить минимум __75%__ точности на валидации.\n",
        "\n",
        "__ХАК_ДНЯ__ : количество каналов должно быть в порядке количества class_labels\n",
        "\n",
        "__ХАК_ДНЯ_2__ : вы можете поставить stride=2 для Conv2d слоя чтобы увеличить скорость обучения, но помните про размерности"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = nn.Sequential()\n",
        "\n",
        "# Your code here: CONV->POOL->CONV-POOL->... as many as you wish\n",
        "# 1\n",
        "model_cnn.add_module('conv1', nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3))\n",
        "model_cnn.add_module('relu1', nn.ReLU())\n",
        "model_cnn.add_module('pool1', nn.MaxPool2d(2))\n",
        "# 2\n",
        "model_cnn.add_module('conv2', nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3))\n",
        "model_cnn.add_module('relu2', nn.ReLU())\n",
        "model_cnn.add_module('pool2', nn.MaxPool2d(2))\n",
        "# 3\n",
        "model_cnn.add_module('conv3', nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3))\n",
        "model_cnn.add_module('relu3', nn.ReLU())\n",
        "model_cnn.add_module('pool3', nn.MaxPool2d(2))\n",
        "# End of your code here\n",
        "# End of your code here\n",
        "# global average pooling\n",
        "model_cnn.add_module('gap_5', nn.AvgPool2d(10))\n",
        "# dropout for regularization\n",
        "model_cnn.add_module('dropout_5', nn.Dropout(0.3))\n",
        "# \"flatten\" the data\n",
        "model_cnn.add_module('flat', nn.Flatten())\n",
        "# last fully-connected layer, used to create embedding vectors\n",
        "model_cnn.add_module('fc_6', nn.Linear(128, EMBEDDING_SIZE))\n",
        "model_cnn.add_module('relu_6', nn.ReLU())\n",
        "\n",
        "model_cnn.add_module('dropout_6', nn.Dropout(0.3))\n",
        "\n",
        "# logits for NUM_CLASSES=2 classes\n",
        "model_cnn.add_module('fc_logits', nn.Linear(EMBEDDING_SIZE, NUM_CLASSES))\n",
        "model_cnn.add_module('fc_preds', nn.Sigmoid())\n",
        "\n",
        "# move model to computing device\n",
        "model_cnn = model_cnn.to(device)"
      ],
      "metadata": {
        "id": "dnzjF2Q16qVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxZ1lYqpV7Sw"
      },
      "source": [
        "\n",
        "__Подсказка:__ Можно не считать размерности слоев руками, просто вставьте любую размерность и запуститите (например, 1 юнит) и  запустите compute_loss. Вы увидите что-то в духе:\n",
        "\n",
        "__`RuntimeError: size mismatch, m1: [5 x 1960], m2: [1 x 64] at /some/long/path/to/torch/operation`__\n",
        "\n",
        "Видите __1960__? Это та размерность, которую вам нужно выставить."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdqMYf-fWbZi"
      },
      "source": [
        "summary(model_cnn, train_dataset[0][0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:33:15.099833Z",
          "start_time": "2021-04-17T09:33:15.095846Z"
        },
        "id": "QXb0NQzxV7Sw"
      },
      "source": [
        "# Оптимайзер\n",
        "opt = torch.optim.Adam(params=model_cnn.parameters(), lr=3e-4)\n",
        "\n",
        "# Функция потерь (Лосс функция)\n",
        "loss_fn =  nn.CrossEntropyLoss()\n",
        "\n",
        "# Число эпох\n",
        "n_epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:32:09.317666Z",
          "start_time": "2021-04-17T09:32:09.305678Z"
        },
        "id": "s67hp0JeV7Sx"
      },
      "source": [
        "opt.zero_grad()\n",
        "train_loss, val_accuracy = train_model(model_cnn,\n",
        "                                         train_loader,\n",
        "                                         val_loader,\n",
        "                                         loss_fn,\n",
        "                                         opt,\n",
        "                                         n_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NolBHw_jV7Sx"
      },
      "source": [
        "def test_model(model, test_loader, subset='test'):\n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    test_batch_acc = []\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        logits = model(X_batch.to(device))\n",
        "        y_pred = logits.max(1)[1].data\n",
        "        test_batch_acc.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
        "\n",
        "    test_accuracy = np.mean(test_batch_acc)\n",
        "    \n",
        "    print(\"Results:\")\n",
        "    print(f\"  {subset} accuracy:\\t\\t{test_accuracy * 100:.2f} %\")\n",
        "    if test_accuracy > 0.9:\n",
        "        print(\"Amazing!\")\n",
        "    elif test_accuracy > 0.7:\n",
        "        print(\"Good!\")\n",
        "    else:\n",
        "        print(\"We need more magic! Follow instructons below\")\n",
        "    return test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0vn_sEQV7Sx"
      },
      "source": [
        "best_model_cnn = model_cnn\n",
        "\n",
        "val_accuracy = test_model(best_model_cnn, val_loader, subset='val')\n",
        "test_accuracy = test_model(best_model_cnn, test_loader, subset='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccLKfj1cV7Sy"
      },
      "source": [
        "__Конец первой части__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iacZz7qV7Sy"
      },
      "source": [
        "# CVAE  (0.3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJcdOwj_V7Sy"
      },
      "source": [
        "Теперь построим CVAE модель. Её отличие в том, что на вход энкодеру и декодеру подаётся значение цифры. Таким образом, модели уже не нужно запоминать значение цифры в латентном коде, т.к. одно добавляется нами вручную.\n",
        "\n",
        "**Упражнение:** Реализуйте CVAE, модифицировав VAE с использованием полносвязных слоёв, который был разобран в начале семинара. \n",
        "\n",
        "Значения лэйблов (y) в виде one-hot векторов нужно присоединить (конкатенировать) к векторам, которые подаются на вход энкодеру и декодеру.\n",
        "\n",
        "Для получение one-hot векторов используйте функцию F.one_hot(input, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:52:11.149056Z",
          "start_time": "2021-04-17T09:52:11.136060Z"
        },
        "id": "8gYRi9_6V7Sy"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from ipywidgets import interact\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "import pylab as pl\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "from functools import reduce"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:52:18.629825Z",
          "start_time": "2021-04-17T09:52:18.624836Z"
        },
        "id": "0UB-ki4sV7Sz"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:52:52.629342Z",
          "start_time": "2021-04-17T09:52:52.605407Z"
        },
        "id": "gEyqeaZiV7Sz"
      },
      "source": [
        "# MNIST dataset\n",
        "dataset = torchvision.datasets.MNIST(root='/content/drive/MyDrive/hw_01_2/',\n",
        "                                     train=True,\n",
        "                                     transform=transforms.ToTensor(),\n",
        "                                     download=True)\n",
        "\n",
        "# Data loader\n",
        "batch_size = 32\n",
        "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:52:52.917573Z",
          "start_time": "2021-04-17T09:52:52.905604Z"
        },
        "id": "Qk0P8oy7V7S0"
      },
      "source": [
        "@interact(i=(0, len(dataset)-1))\n",
        "def f(i):\n",
        "    print(dataset[i][1])\n",
        "    plt.imshow(dataset[i][0].numpy()[0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBHUdWnmnGcg"
      },
      "source": [
        "#Создаем модель\n",
        "#Your code goes here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-psxxNbrV7S0"
      },
      "source": [
        "# CVAE model\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, image_size=28*28, z_size=20):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.image_size = image_size\n",
        "        self.fc1 = nn.Linear(self.image_size + 10, 400)\n",
        "\n",
        "        self.fc2 = nn.Linear(400, 128)\n",
        "        self.fc3 = nn.Linear(128, z_size)\n",
        "        self.fc4 = nn.Linear(128, z_size)\n",
        "        self.fc5 = nn.Linear(z_size + 10, 400)\n",
        "\n",
        "        self.fc6 = nn.Linear(400, self.image_size)\n",
        "        \n",
        "    def encode(self, x, y):\n",
        "        x = torch.concat((x.flatten(1), F.one_hot(y, 10)), dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x), self.fc4(x)\n",
        "    \n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(log_var/2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z, y):\n",
        "        z = torch.concat((z, F.one_hot(y, 10)), dim=1)\n",
        "        x = F.relu(self.fc5(z))\n",
        "        return F.sigmoid(self.fc6(x))\n",
        "    \n",
        "    def forward(self, x, y):\n",
        "        mu, log_var = self.encode(x, y)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        out = self.decode(z, y)\n",
        "        x_reconst = torch.reshape(out, (-1, 1, int(np.sqrt(self.image_size)), int(np.sqrt(self.image_size))))\n",
        "        return x_reconst, mu, log_var"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh0mNt3VV7S1"
      },
      "source": [
        "def train(model, data_reader, optimizer, num_epochs=2):\n",
        "    # Start training\n",
        "    loss1 = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (x, y) in enumerate(data_loader):\n",
        "            # Forward pass\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            x_reconst, mu, log_var = model(x, y)\n",
        "\n",
        "            # Compute reconstruction loss and kl divergence\n",
        "            reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
        "            kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "            # Backprop and optimize\n",
        "            loss = reconst_loss + kl_div\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                loss1.append(loss.item())\n",
        "                pl.plot(loss1, color='red')\n",
        "                display.clear_output(wait=True)\n",
        "                display.display(pl.gcf())\n",
        "                print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
        "                      .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4VaixgCV7S1"
      },
      "source": [
        "model = CVAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "train(model, data_loader, optimizer, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quHtp6N7V7S2"
      },
      "source": [
        "n = 10\n",
        "im_size = 28\n",
        "from scipy.stats import norm\n",
        "# Так как сэмплируем из N(0, I), то сетку узлов, в которых генерируем цифры, берем из обратной функции распределения\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "def draw_manifold(model, lbl, show=True):\n",
        "    with torch.no_grad():\n",
        "        # Рисование цифр из многообразия\n",
        "        figure = np.zeros((im_size * n, im_size * n))\n",
        "        input_lbl = np.zeros((1, 10))\n",
        "        input_lbl[0, lbl] = 1\n",
        "        for i, yi in enumerate(grid_y):\n",
        "            for j, xi in enumerate(grid_x):\n",
        "                z_sample = np.zeros((1, 20))\n",
        "                z_sample[:, :2] = np.array([[xi, yi]])\n",
        "                z_sample = torch.tensor(z_sample, dtype=torch.float).to(device)\n",
        "                input_lbl = torch.tensor(input_lbl, dtype=torch.float).to(device)\n",
        "                x_decoded = model.decode(z_sample, torch.tensor(lbl).reshape(-1)).cpu().numpy().reshape((im_size, im_size))\n",
        "                digit = x_decoded.squeeze() \n",
        "                figure[i * im_size: (i + 1) * im_size,\n",
        "                    j * im_size: (j + 1) * im_size] = digit\n",
        "        if show:\n",
        "            # Визуализация\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.imshow(figure, cmap='gray')\n",
        "            plt.grid(False)\n",
        "            ax = plt.gca()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "            plt.show()\n",
        "    return figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV5L0xw5V7S2"
      },
      "source": [
        "for i in range(10):\n",
        "    draw_manifold(model, i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSKNDpZfV7S2"
      },
      "source": [
        "# GAN 0.3 балла"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T09:57:45.770866Z",
          "start_time": "2021-04-17T09:57:45.687089Z"
        },
        "id": "jkK08CQUV7S3"
      },
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as tt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuKl0tnGV7S3"
      },
      "source": [
        "!wget https://www.dropbox.com/s/329oy3cprlvn5vb/archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY4uINpPV7S3"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('archive.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phCOXQj_V7S3"
      },
      "source": [
        "DATA_DIR = './cats/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ask2vXx9V7S4"
      },
      "source": [
        "# set parameters of the transformed data\n",
        "image_size = 64\n",
        "batch_size = 128\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb5RZA81V7S4"
      },
      "source": [
        "# As dataset is stored in the directory, we can create dataset\n",
        "# as ImageFolder PyTorch object and set all the transformations here\n",
        "train_ds = ImageFolder(DATA_DIR, transform=tt.Compose([\n",
        "    tt.ToTensor(),\n",
        "    tt.Normalize(*stats)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcX3TiTtV7S4"
      },
      "source": [
        "# Create PyTorch DataLoader object to produce batches\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP8z4DF4V7S4"
      },
      "source": [
        "# for the nicer images visualization \n",
        "# we make inverse transformation for normalization\n",
        "def denorm(img_tensors):\n",
        "    return img_tensors * stats[1][0] + stats[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii8EDftgV7S5"
      },
      "source": [
        "# functions to plot images\n",
        "def show_images(images, nmax=64):\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
        "\n",
        "def show_batch(dl, nmax=64):\n",
        "    for images, _ in dl:\n",
        "        show_images(images, nmax)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAS1Zk7tV7S5"
      },
      "source": [
        "show_batch(train_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftJGY_IuV7S5"
      },
      "source": [
        "# Utils functions for GPU usage of neural networks\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSLHkKZpV7S6"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twxj0zfgV7S6"
      },
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YlYVv8wV7S6"
      },
      "source": [
        "discriminator = nn.Sequential(\n",
        "    # in: 3 x 64 x 64\n",
        "\n",
        "    nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # out: 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjf3ZI9cV7S6"
      },
      "source": [
        "discriminator = to_device(discriminator, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK-nSz7mV7S7"
      },
      "source": [
        "latent_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8-Ao8TbV7S7"
      },
      "source": [
        "generator = nn.Sequential(\n",
        "    # in: latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    # out: 3 x 64 x 64\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCI8O3S6V7S7"
      },
      "source": [
        "xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors\n",
        "fake_images = generator(xb)\n",
        "print(fake_images.shape)\n",
        "show_images(fake_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFXxIOpyV7S8"
      },
      "source": [
        "generator = to_device(generator, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH8w0n5BV7S8"
      },
      "source": [
        "def train_discriminator(real_images, opt_d):\n",
        "    # Clear discriminator gradients\n",
        "    opt_d.zero_grad()\n",
        "\n",
        "    # Pass real images through discriminator\n",
        "    real_preds = discriminator(real_images)\n",
        "    real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
        "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
        "    real_score = torch.mean(real_preds).item()\n",
        "    \n",
        "    # Generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "    fake_images = generator(latent)\n",
        "\n",
        "    # Pass fake images through discriminator\n",
        "    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
        "    fake_preds = discriminator(fake_images)\n",
        "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
        "    fake_score = torch.mean(fake_preds).item()\n",
        "\n",
        "    # Update discriminator weights\n",
        "    loss = real_loss + fake_loss\n",
        "    loss.backward()\n",
        "    opt_d.step()\n",
        "    return loss.item(), real_score, fake_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUUTN8oGV7S8"
      },
      "source": [
        "def train_generator(opt_g):\n",
        "    # Clear generator gradients\n",
        "    opt_g.zero_grad()\n",
        "    \n",
        "    # Generate fake images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "    fake_images = generator(latent)\n",
        "    \n",
        "    # Try to fool the discriminator\n",
        "    preds = discriminator(fake_images)\n",
        "    targets = torch.ones(batch_size, 1, device=device)\n",
        "    loss = F.binary_cross_entropy(preds, targets)\n",
        "    \n",
        "    # Update generator weights\n",
        "    loss.backward()\n",
        "    opt_g.step()\n",
        "    \n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pZfVQcOV7S9"
      },
      "source": [
        "sample_dir = 'generated'\n",
        "os.makedirs(sample_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDPo_XfFV7S9"
      },
      "source": [
        "def save_samples(index, latent_tensors, show=True):\n",
        "    fake_images = generator(latent_tensors)\n",
        "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
        "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
        "    print('Saving', fake_fname)\n",
        "    if show:\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(denorm(fake_images).cpu().detach(), nrow=8).permute(1, 2, 0))\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTtzkI4oV7S9"
      },
      "source": [
        "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49_DkWeNV7S9"
      },
      "source": [
        "save_samples(0, fixed_latent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqt6M_zAV7S-"
      },
      "source": [
        "def fit(epochs, lr, start_idx=1):\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Losses & scores\n",
        "    losses_g = []\n",
        "    losses_d = []\n",
        "    real_scores = []\n",
        "    fake_scores = []\n",
        "    \n",
        "    # Create optimizers\n",
        "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for real_images, _ in tqdm(train_dl):\n",
        "            # Train discriminator\n",
        "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
        "            # Train generator\n",
        "            loss_g = train_generator(opt_g)\n",
        "            \n",
        "        # Record losses & scores\n",
        "        losses_g.append(loss_g)\n",
        "        losses_d.append(loss_d)\n",
        "        real_scores.append(real_score)\n",
        "        fake_scores.append(fake_score)\n",
        "        \n",
        "        # Log losses & scores (last batch)\n",
        "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
        "            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
        "    \n",
        "        # Save generated images\n",
        "        save_samples(epoch+start_idx, fixed_latent, show=True)\n",
        "    \n",
        "    return losses_g, losses_d, real_scores, fake_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON7e9yA4V7S-"
      },
      "source": [
        "lr = 0.0002\n",
        "epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnW4NSHYV7S-"
      },
      "source": [
        "history = fit(epochs, lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vhrLBFGV7S-"
      },
      "source": [
        "losses_g, losses_d, real_scores, fake_scores = history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE4LPst6V7S_"
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc-Ds-vQV7S_"
      },
      "source": [
        "Image('./generated/generated-images-0060.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ghRwIQEV7S_"
      },
      "source": [
        "vid_fname = 'gans_training.mp4'\n",
        "\n",
        "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'generated' in f]\n",
        "files.sort()\n",
        "\n",
        "out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 1, (530,530))\n",
        "[out.write(cv2.imread(fname)) for fname in files]\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDFi3Fz7V7S_"
      },
      "source": [
        "plt.plot(losses_d, '-')\n",
        "plt.plot(losses_g, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Discriminator', 'Generator'])\n",
        "plt.title('Losses');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bXf5oKpV7TA"
      },
      "source": [
        "plt.plot(real_scores, '-')\n",
        "plt.plot(fake_scores, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('score')\n",
        "plt.legend(['Real', 'Fake'])\n",
        "plt.title('Scores');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mun7SyNQV7TA"
      },
      "source": [
        "## Улучшаем наш ГАН.\n",
        "\n",
        "\n",
        "1. Попробуйте добавить большеConv-BN блоков в Дискриминатор\n",
        "2. Попробуйте добавить Pooling в Дискриминатор\n",
        "3. Попробуйте добавить больше Conv-BN блоков в Генератор\n",
        "4. Увеличьте `latent_size`\n",
        "5. Попробуйте использовать функцию активации ELU или LeakyReLU\n",
        "\n",
        "Используйте, чтобы получить дополнительные подсказки [source](https://machinelearningmastery.com/how-to-train-stable-generative-adversarial-networks/)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = nn.Sequential(\n",
        "    nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size=3, padding = 1, bias=False),\n",
        "    nn.BatchNorm2d(16),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "    nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size=3, padding = 1, bias=False),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "    nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=3, padding = 1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.MaxPool2d(2),\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=3, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.MaxPool2d(2),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=3, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.MaxPool2d(2),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=3, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.MaxPool2d(2),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # out: 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid()\n",
        "    )"
      ],
      "metadata": {
        "id": "5A9D87GzJGyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ccx52XJZgG"
      },
      "source": [
        "discriminator = to_device(discriminator, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouBErX7ZJZgJ"
      },
      "source": [
        "latent_size = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwkVjICaJZgK"
      },
      "source": [
        "generator = nn.Sequential(\n",
        "    # in: latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 1024, kernel_size=2, bias=False),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(1024, 512, kernel_size=3, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "\n",
        "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = to_device(generator, device)"
      ],
      "metadata": {
        "id": "-88_jhbEJfYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 3e-4\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "aW59NaRZJgQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit(epochs, lr)"
      ],
      "metadata": {
        "id": "X5GguvUkJgXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNzMg4gxV7TA"
      },
      "source": [
        "## Генерируем лица!\n",
        "\n",
        "\n",
        "1. Добавьте CenterCrop трансформацию к изображениями и уменьшите их размер\n",
        "2. Используйте более глубокую GAN модель\n",
        "3. Получите модель, которая выдает приемлимый аутпут с достаточно хорошими лицами (Хорошие - субъективный критерий, сделайте визуализацию и обоснуйте \"хорошесть\" модели)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQyX_hzcV7TA"
      },
      "source": [
        "!wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz -O tmp.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--PLdTXUV7TA"
      },
      "source": [
        "!tar xvzf tmp.tgz && rm tmp.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR-GzoGpV7TB"
      },
      "source": [
        "DATA_DIR = './lfw-deepfunneled/'\n",
        "image_size = 250\n",
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVgRgYhpV7TB"
      },
      "source": [
        "train_ds = ImageFolder(DATA_DIR, transform=tt.Compose([\n",
        "    tt.CenterCrop(128),\n",
        "    tt.Resize(64),\n",
        "    tt.ToTensor(),\n",
        "    tt.Normalize(*stats)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fbytRGnzsv7"
      },
      "source": [
        "# Create PyTorch DataLoader object to produce batches\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)"
      ],
      "metadata": {
        "id": "8iYJohYx3oIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = nn.Sequential(\n",
        "    # in: 3 x 64 x 64\n",
        "\n",
        "    nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # out: 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid())"
      ],
      "metadata": {
        "id": "shvFgpbz2C8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaC5DSCM2OwI"
      },
      "source": [
        "discriminator = to_device(discriminator, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XJ-V8iT2OwK"
      },
      "source": [
        "latent_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC6zov2d2OwM"
      },
      "source": [
        "generator = nn.Sequential(\n",
        "    # in: latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    # out: 3 x 64 x 64\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = to_device(generator, device)"
      ],
      "metadata": {
        "id": "nNBiRkfU299z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_size = 128"
      ],
      "metadata": {
        "id": "qXMmk4jQ2d_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)"
      ],
      "metadata": {
        "id": "zEYOiKEt2ecp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 2e-4\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "b22f3NA62kmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit(epochs, lr)"
      ],
      "metadata": {
        "id": "0csKpaCg2z7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtmnlQpaV7TB"
      },
      "source": [
        "# Дополнительное задание на +0.5 балла"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-17T10:16:29.587457Z",
          "start_time": "2021-04-17T10:16:29.580484Z"
        },
        "id": "p3Mr4BhrV7TB"
      },
      "source": [
        "Overfit it\n",
        "Будем работать с датасетом Fashion-MNIST (hint: он доступен в torchvision) https://github.com/zalandoresearch/fashion-mnist.\n",
        "\n",
        "Ваша задача состоит в следующем:\n",
        "\n",
        "Обучить сеть, которая покажет >= 0.92 test accuracy.\n",
        "Пронаблюдать и продемонстрировать процесс переобучения сети с увеличением числа параметров (==нейронов) и/или числа слоев и продемонстрировать это наглядно (например, на графиках).\n",
        "Попробовать частично справиться с переобучением с помощью подходящих приемов (Dropout/batchnorm/augmentation etc.)\n",
        "Примечание: Пункты 2 и 3 взаимосвязаны, в п.3 Вам прелагается сделать полученную в п.2 сеть менее склонной к переобучению. Пункт 1 является независимым от пунктов 2 и 3."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.1 Finetuning: >= 0.92 test accuracy"
      ],
      "metadata": {
        "id": "nGVBsOilb8AA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7tu0EWWV7TC"
      },
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "DYlebdYWdWQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "eE8QW26vfEdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "m1iFZGfzgp55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "8Gf-sBW-e8xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train dataset\n",
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root = '/content/data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "5H8MO1JscIxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset\n",
        "test_set = torchvision.datasets.FashionMNIST(\n",
        "    root = '/content/data',\n",
        "    train = False,\n",
        "    download = False,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()                                 \n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "GP_KKdg3dPhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        label = self.dataset[index][1]\n",
        "        image = self.dataset[index][0]\n",
        "        image = torch.cat([image, image, image], 0)\n",
        "        image = transforms.ToPILImage()(image)\n",
        "        image = image.resize((224, 224))\n",
        "        image = transforms.ToTensor()(image)\n",
        "        image = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(image) \n",
        "        return image, label\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.dataset)"
      ],
      "metadata": {
        "id": "dSAEGMxCO6B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_train_set = CustomDataset(train_set)\n",
        "custom_test_set = CustomDataset(test_set)"
      ],
      "metadata": {
        "id": "5mdzJ05pcF01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "CLASSES = 10\n",
        "EPOCHS = 2\n",
        "LR = 3e-4\n",
        "\n",
        "loss_fn =  nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "XKWM6m7depvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "hAoJML5TgQ4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, CLASSES)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "kYCaREL8fHZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    custom_train_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        "    )"
      ],
      "metadata": {
        "id": "j8yxC2HYd-6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    custom_test_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        "    )"
      ],
      "metadata": {
        "id": "8XH-Mj3LfYAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, loss_fn, device):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for data in tqdm(data_loader):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        total_loss += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "g4BIdFD_fd5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, data_loader, loss_fn, device):\n",
        "    predicted = []\n",
        "    labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(data_loader):\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "\n",
        "            outputs = model(x)\n",
        "            _, predict = torch.max(outputs.data, 1)\n",
        "            predict = predict.cpu().detach().numpy().tolist()\n",
        "            predicted += predict\n",
        "            labels += y\n",
        "    return accuracy_score(labels, predicted)"
      ],
      "metadata": {
        "id": "gvy7ck_gfk2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(train_nn(model, train_data_loader, loss_fn, device))\n",
        "    print(eval(model, test_data_loader, loss_fn, device))"
      ],
      "metadata": {
        "id": "-Z_85qUdfk5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Продемонстрировать процесс переобучения сети"
      ],
      "metadata": {
        "id": "IP59F2uEn_BT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "CLASSES = 10\n",
        "EPOCHS = 100\n",
        "LR = 3e-4\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "puR4qRMKrWnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        "    )"
      ],
      "metadata": {
        "id": "vHjVpHe_rNaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        "    )"
      ],
      "metadata": {
        "id": "stGR0mMXrPOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = nn.Sequential()\n",
        "\n",
        "model_cnn.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3))\n",
        "# model_cnn.add_module('norm1', nn.BatchNorm2d(64))\n",
        "model_cnn.add_module('relu1', nn.ReLU())\n",
        "model_cnn.add_module('pool1', nn.MaxPool2d(2))\n",
        "\n",
        "model_cnn.add_module('conv2', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3))\n",
        "# model_cnn.add_module('norm2', nn.BatchNorm2d(128))\n",
        "model_cnn.add_module('relu2', nn.ReLU())\n",
        "model_cnn.add_module('pool2', nn.MaxPool2d(2))\n",
        "\n",
        "model_cnn.add_module('conv3', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3))\n",
        "# model_cnn.add_module('norm3', nn.BatchNorm2d(256))\n",
        "model_cnn.add_module('relu3', nn.ReLU())\n",
        "model_cnn.add_module('pool3', nn.MaxPool2d(2))\n",
        "\n",
        "# model_cnn.add_module('dropout_5', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('flat', nn.Flatten())\n",
        "\n",
        "model_cnn.add_module('fc_6', nn.Linear(256, 512))\n",
        "model_cnn.add_module('relu_6', nn.ReLU())\n",
        "# model_cnn.add_module('dropout_6', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('fc_7', nn.Linear(512, 256))\n",
        "model_cnn.add_module('relu_7', nn.ReLU())\n",
        "# model_cnn.add_module('dropout_7', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('fc_logits', nn.Linear(256, CLASSES))\n",
        "model_cnn.add_module('fc_preds', nn.Sigmoid())\n",
        "\n",
        "model_cnn = model_cnn.to(device)"
      ],
      "metadata": {
        "id": "JLsvsF4kkHSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model_cnn.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "0qgMS2C4gY35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_0 = []\n",
        "test_acc_0 = []\n",
        "loss_0 = []\n",
        "for epoch in range(EPOCHS):\n",
        "    loss_0.append(train(model_cnn, train_data_loader, loss_fn, device))\n",
        "    train_acc_0.append(eval(model_cnn, train_data_loader, loss_fn, device))\n",
        "    test_acc_0.append(eval(model_cnn, test_data_loader, loss_fn, device))"
      ],
      "metadata": {
        "id": "WaIEdodMgimg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_acc_0)\n",
        "plt.plot(test_acc_0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EP-uYwEAsxed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Cправиться с переобучением: dropout/batchnorm/augmentation"
      ],
      "metadata": {
        "id": "QinCDWQeu4O_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout"
      ],
      "metadata": {
        "id": "zqz4-MO0vbEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = nn.Sequential()\n",
        "\n",
        "model_cnn.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3))\n",
        "# model_cnn.add_module('norm1', nn.BatchNorm2d(64))\n",
        "model_cnn.add_module('relu1', nn.ReLU())\n",
        "model_cnn.add_module('pool1', nn.MaxPool2d(2))\n",
        "\n",
        "model_cnn.add_module('conv2', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3))\n",
        "# model_cnn.add_module('norm2', nn.BatchNorm2d(128))\n",
        "model_cnn.add_module('relu2', nn.ReLU())\n",
        "model_cnn.add_module('pool2', nn.MaxPool2d(2))\n",
        "\n",
        "model_cnn.add_module('conv3', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3))\n",
        "# model_cnn.add_module('norm3', nn.BatchNorm2d(256))\n",
        "model_cnn.add_module('relu3', nn.ReLU())\n",
        "model_cnn.add_module('pool3', nn.MaxPool2d(2))\n",
        "\n",
        "model_cnn.add_module('dropout_5', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('flat', nn.Flatten())\n",
        "\n",
        "model_cnn.add_module('fc_6', nn.Linear(256, 512))\n",
        "model_cnn.add_module('relu_6', nn.ReLU())\n",
        "model_cnn.add_module('dropout_6', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('fc_7', nn.Linear(512, 256))\n",
        "model_cnn.add_module('relu_7', nn.ReLU())\n",
        "model_cnn.add_module('dropout_7', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('fc_logits', nn.Linear(256, CLASSES))\n",
        "model_cnn.add_module('fc_preds', nn.Sigmoid())\n",
        "\n",
        "model_cnn = model_cnn.to(device)"
      ],
      "metadata": {
        "id": "Z0GykkPuu-xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model_cnn.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "rs2vTRmwvHI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_1 = []\n",
        "test_acc_1 = []\n",
        "loss_1 = []\n",
        "for epoch in range(EPOCHS):\n",
        "    loss_1.append(train(model_cnn, train_data_loader, loss_fn, device))\n",
        "    train_acc_1.append(eval(model_cnn, train_data_loader, loss_fn, device))\n",
        "    test_acc_1.append(eval(model_cnn, test_data_loader, loss_fn, device))"
      ],
      "metadata": {
        "id": "K8TR2xBdvJXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc_1)\n",
        "plt.plot(test_acc_1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NjIITm0AvL0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batchnorm"
      ],
      "metadata": {
        "id": "kBmZTxY3vf_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = nn.Sequential()\n",
        "\n",
        "model_cnn.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3))\n",
        "model_cnn.add_module('norm1', nn.BatchNorm2d(64))\n",
        "model_cnn.add_module('relu1', nn.ReLU())\n",
        "model_cnn.add_module('pool1', nn.MaxPool2d(2))\n",
        "\n",
        "model_cnn.add_module('conv2', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3))\n",
        "model_cnn.add_module('norm2', nn.BatchNorm2d(128))\n",
        "model_cnn.add_module('relu2', nn.ReLU())\n",
        "model_cnn.add_module('pool2', nn.MaxPool2d(2))\n",
        "\n",
        "model_cnn.add_module('conv3', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3))\n",
        "model_cnn.add_module('norm3', nn.BatchNorm2d(256))\n",
        "model_cnn.add_module('relu3', nn.ReLU())\n",
        "model_cnn.add_module('pool3', nn.MaxPool2d(2))\n",
        "\n",
        "model_cnn.add_module('dropout_5', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('flat', nn.Flatten())\n",
        "\n",
        "model_cnn.add_module('fc_6', nn.Linear(256, 512))\n",
        "model_cnn.add_module('relu_6', nn.ReLU())\n",
        "model_cnn.add_module('dropout_6', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('fc_7', nn.Linear(512, 256))\n",
        "model_cnn.add_module('relu_7', nn.ReLU())\n",
        "model_cnn.add_module('dropout_7', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('fc_logits', nn.Linear(256, CLASSES))\n",
        "model_cnn.add_module('fc_preds', nn.Sigmoid())\n",
        "\n",
        "model_cnn = model_cnn.to(device)"
      ],
      "metadata": {
        "id": "mz5__h2zvn_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model_cnn.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "XvEQE4Zivq5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_2 = []\n",
        "test_acc_2 = []\n",
        "loss_2 = []\n",
        "for epoch in range(EPOCHS):\n",
        "    loss_2.append(train(model_cnn, train_data_loader, loss_fn, device))\n",
        "    train_acc_2.append(eval(model_cnn, train_data_loader, loss_fn, device))\n",
        "    test_acc_2.append(eval(model_cnn, test_data_loader, loss_fn, device))"
      ],
      "metadata": {
        "id": "VI31QX5Qvq5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc_2)\n",
        "plt.plot(test_acc_2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6-EIjD9wvq5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Augmentation"
      ],
      "metadata": {
        "id": "URye_ZPpvhQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretrain"
      ],
      "metadata": {
        "id": "YGyRvIY_LOMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "CLASSES = 10\n",
        "EPOCHS = 20\n",
        "LR = 3e-4\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "snUCToxmLKx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        "    )"
      ],
      "metadata": {
        "id": "OEy_9HE2Dcgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        "    )"
      ],
      "metadata": {
        "id": "VJZp6G4YDcgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = nn.Sequential()\n",
        "\n",
        "model_cnn.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3))\n",
        "model_cnn.add_module('norm1', nn.BatchNorm2d(64))\n",
        "model_cnn.add_module('relu1', nn.ReLU())\n",
        "model_cnn.add_module('pool1', nn.MaxPool2d(2))\n",
        "\n",
        "model_cnn.add_module('conv2', nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3))\n",
        "model_cnn.add_module('norm2', nn.BatchNorm2d(128))\n",
        "model_cnn.add_module('relu2', nn.ReLU())\n",
        "model_cnn.add_module('pool2', nn.MaxPool2d(2))\n",
        "\n",
        "model_cnn.add_module('conv3', nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3))\n",
        "model_cnn.add_module('norm3', nn.BatchNorm2d(256))\n",
        "model_cnn.add_module('relu3', nn.ReLU())\n",
        "model_cnn.add_module('pool3', nn.MaxPool2d(2))\n",
        "\n",
        "model_cnn.add_module('dropout_5', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('flat', nn.Flatten())\n",
        "\n",
        "model_cnn.add_module('fc_6', nn.Linear(256, 512))\n",
        "model_cnn.add_module('relu_6', nn.ReLU())\n",
        "model_cnn.add_module('dropout_6', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('fc_7', nn.Linear(512, 256))\n",
        "model_cnn.add_module('relu_7', nn.ReLU())\n",
        "model_cnn.add_module('dropout_7', nn.Dropout(0.3))\n",
        "\n",
        "model_cnn.add_module('fc_logits', nn.Linear(256, CLASSES))\n",
        "model_cnn.add_module('fc_preds', nn.Sigmoid())\n",
        "\n",
        "model_cnn = model_cnn.to(device)"
      ],
      "metadata": {
        "id": "h66jTHrRD1Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model_cnn.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "ROxBKeSJD1Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_3 = []\n",
        "test_acc_3 = []\n",
        "loss_3 = []\n",
        "for epoch in range(EPOCHS):\n",
        "    loss = train(model_cnn, train_data_loader, loss_fn, device)\n",
        "    train_acc = eval(model_cnn, train_data_loader, loss_fn, device)\n",
        "    test_acc = eval(model_cnn, test_data_loader, loss_fn, device)\n",
        "    loss_3.append(loss)\n",
        "    train_acc_3.append(train_acc)\n",
        "    test_acc_3.append(test_acc)\n",
        "    print(epoch, loss, train_acc, test_acc)"
      ],
      "metadata": {
        "id": "M2xVUMf-D1Cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc_3)\n",
        "plt.plot(test_acc_3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rgylnj6aJEMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation"
      ],
      "metadata": {
        "id": "BAyriU4DLUnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "CLASSES = 10\n",
        "EPOCHS = 100\n",
        "LR = 3e-4"
      ],
      "metadata": {
        "id": "HWDzZ1HPL0uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDatasetAug(Dataset):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        label = self.dataset[index][1]\n",
        "        image = self.dataset[index][0]\n",
        "        image = transforms.ToPILImage()(image)\n",
        "        # image = image.resize((32, 32))\n",
        "        # image = transforms.RandomCrop(28)(image)\n",
        "        image = transforms.RandomHorizontalFlip()(image)\n",
        "        # image = transforms.RandomPerspective()(image)\n",
        "        image = transforms.RandomRotation(15)(image)\n",
        "        # image = transforms.RandomVerticalFlip()(image)\n",
        "        image = transforms.ToTensor()(image)\n",
        "        # image = transforms.Normalize((0.5), (0.5))(image)\n",
        "        return image, label\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.dataset)"
      ],
      "metadata": {
        "id": "KFGnrr-ABiZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_train_set = CustomDatasetAug(train_set)"
      ],
      "metadata": {
        "id": "ae30NlMNLXh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    custom_train_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        "    )"
      ],
      "metadata": {
        "id": "90u3aOsLLkmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        "    )"
      ],
      "metadata": {
        "id": "csQASx3NLxkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_aug = []\n",
        "test_acc_aug = []\n",
        "loss_aug = []\n",
        "for epoch in range(EPOCHS):\n",
        "    loss = train(model_cnn, train_data_loader, loss_fn, device)\n",
        "    train_acc = eval(model_cnn, train_data_loader, loss_fn, device)\n",
        "    test_acc = eval(model_cnn, test_data_loader, loss_fn, device)\n",
        "    loss_aug.append(loss)\n",
        "    train_acc_aug.append(train_acc)\n",
        "    test_acc_aug.append(test_acc)\n",
        "    print(epoch, loss, train_acc, test_acc)"
      ],
      "metadata": {
        "id": "0Bjrx8ZVL6YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc_aug)\n",
        "plt.plot(test_acc_aug)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZAYqya2yMBrM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}