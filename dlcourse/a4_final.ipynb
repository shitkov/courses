{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"a4_final.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMnyA/0Lr2dDOUfP1Df2OIs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"8isaGjIOomt9","colab_type":"code","outputId":"b5abd9e5-144c-492e-acbc-048c4563b493","executionInfo":{"status":"ok","timestamp":1589997526741,"user_tz":-180,"elapsed":1087,"user":{"displayName":"Константин Шитьков","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCkCq5x25vNYZBSH3vcpBiuv_VP9JI0RltsyLT-g=s64","userId":"04248095687395188930"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JZKOmq7EP9x3","colab_type":"code","colab":{}},"source":["!pip3 install -q torch torchvision\n","!pip3 install -q Pillow\n","import os\n","import json\n","import os\n","import csv\n","import urllib\n","from io import BytesIO\n","from PIL import Image\n","from socket import timeout\n","from google.colab import files\n","import torch\n","from torchvision import models\n","from torch.utils.data import Dataset, SubsetRandomSampler\n","from torchvision import transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pr8P52v6pv7K","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","import sklearn.metrics as metrics"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e76QPJalQbjs","colab_type":"code","outputId":"d18d4fb6-ed6b-4cef-9f93-ff4b0d7333bc","executionInfo":{"status":"ok","timestamp":1589991377082,"user_tz":-180,"elapsed":120030,"user":{"displayName":"Константин Шитьков","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCkCq5x25vNYZBSH3vcpBiuv_VP9JI0RltsyLT-g=s64","userId":"04248095687395188930"}},"colab":{"base_uri":"https://localhost:8080/","height":404}},"source":["# Download train data\n","!wget \"https://storage.googleapis.com/dlcourse_ai/train.zip\"\n","!unzip -q \"train.zip\"\n","\n","# Download test data\n","!wget \"https://storage.googleapis.com/dlcourse_ai/test.zip\"\n","!unzip -q \"test.zip\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-05-20 16:15:48--  https://storage.googleapis.com/dlcourse_ai/train.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 2404:6800:4008:c04::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 562348083 (536M) [application/zip]\n","Saving to: ‘train.zip’\n","\n","train.zip           100%[===================>] 536.30M  44.9MB/s    in 12s     \n","\n","2020-05-20 16:16:01 (44.6 MB/s) - ‘train.zip’ saved [562348083/562348083]\n","\n","--2020-05-20 16:16:09--  https://storage.googleapis.com/dlcourse_ai/test.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 2404:6800:4008:c07::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 140788786 (134M) [application/zip]\n","Saving to: ‘test.zip’\n","\n","test.zip            100%[===================>] 134.27M  43.9MB/s    in 3.1s    \n","\n","2020-05-20 16:16:13 (43.9 MB/s) - ‘test.zip’ saved [140788786/140788786]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cdI2IzMGQa53","colab_type":"code","colab":{}},"source":["# Let's make sure GPU is available!\n","device = torch.device(\"cuda:0\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bu7fRG5eQejm","colab_type":"code","colab":{}},"source":["train_folder = '/content/train_kaggle/'\n","test_folder = '/content/test_kaggle/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5a0hYIHJQfBQ","colab_type":"code","colab":{}},"source":["class HotdogOrNotDataset(Dataset):\n","    def __init__(self, folder, transform=None):\n","        self.transform = transform\n","        self.folder = folder\n","        self.files = [f for f in os.listdir(self.folder) if os.path.isfile(os.path.join(self.folder, f))]\n","        \n","    def __len__(self):\n","        return len(self.files)\n","    \n","    def __getitem__(self, index):\n","        # create reading image file\n","        if torch.is_tensor(index):\n","            index = index.tolist()\n","\n","        img_name = os.path.join(self.folder + self.files[index])\n","        \n","        img = Image.open(img_name)\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        prefix = self.files[index].split('_')[0]\n","        if prefix in ['frankfurter', 'chili-dog', 'hotdog']:\n","            y = 1\n","        else:\n","            y = 0\n","\n","        img_id = self.files[index]\n","        return img, y, img_id"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gkoU5-MTpeMI","colab_type":"code","colab":{}},"source":["def train_model(model, train_loader, val_loader, train_dataset, val_indices, loss, optimizer, num_epochs, step_size, gamma):    \n","    loss_history = []\n","    train_history = []\n","    val_history = []\n","\n","    best_model = model\n","    best_f1 = 0\n","\n","    for epoch in range(num_epochs):\n","        model.train() # Enter train mode\n","        \n","        loss_accum = 0\n","        correct_samples = 0\n","        total_samples = 0\n","\n","        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","\n","        for i_step, (x, y,_) in enumerate(train_loader):\n","          \n","            x_gpu = x.to(device)\n","            y_gpu = y.to(device)\n","            prediction = model(x_gpu)    \n","            loss_value = loss(prediction, y_gpu)\n","            optimizer.zero_grad()\n","            loss_value.backward()\n","            optimizer.step()\n","            \n","            _, indices = torch.max(prediction, 1)\n","            correct_samples += torch.sum(indices == y_gpu)\n","            total_samples += y.shape[0]\n","            \n","            loss_accum += loss_value\n","\n","        scheduler.step()\n","\n","        ave_loss = loss_accum / i_step\n","        train_accuracy = float(correct_samples) / total_samples\n","        val_accuracy = compute_accuracy(model, val_loader)\n","        \n","        loss_history.append(float(ave_loss))\n","        train_history.append(train_accuracy)\n","        val_history.append(val_accuracy)\n","\n","        predictions, gt = evaluate_model(model, train_dataset, val_indices)\n","\n","        precision, recall, f1 = binary_classification_metrics(predictions, gt)        \n","        \n","        print(\"Epoch:\", epoch)\n","        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n","        print(\"F1: %4.3f, P: %4.3f, R: %4.3f\" % (f1, precision, recall))\n","\n","        if f1 > best_f1:\n","            best_model = model\n","            best_f1 = f1\n","            \n","    return best_model        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vz9lA59RphTg","colab_type":"code","colab":{}},"source":["def compute_accuracy(model, loader):\n","    \"\"\"\n","    Computes accuracy on the dataset wrapped in a loader\n","    \n","    Returns: accuracy as a float value between 0 and 1\n","    \"\"\"\n","    model.eval() # Evaluation mode\n","    \n","    # TODO: Copy implementation from previous assignment\n","    # Don't forget to move the data to device before running it through the model!\n","    \n","    # raise Exception(\"Not implemented\")\n","    accuracy = 0\n","    steps = 0\n","    for i_step, (x, y,_) in enumerate(loader):\n","\n","        x_gpu = x.to(device)\n","        y_gpu = y.to(device)\n","\n","        prediction = torch.argmax(model(x_gpu), dim=1)\n","        \n","        for i in range(len(y_gpu)):\n","            if prediction[i] == y_gpu[i]:\n","                accuracy += 1\n","            \n","            steps += 1\n","            \n","    accuracy = accuracy/(steps)\n","        \n","    return accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TXkffI7PpjJd","colab_type":"code","colab":{}},"source":["def create_train_dataset(train_folder):\n","    train_dataset = HotdogOrNotDataset(train_folder, \n","                          transform=transforms.Compose([\n","                              transforms.Resize((224, 224)),\n","                              transforms.ToTensor(),\n","                              # Use mean and std for pretrained models\n","                              # https://pytorch.org/docs/stable/torchvision/models.html\n","                              transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                    std=[0.229, 0.224, 0.225])                         \n","                          ])\n","                          )\n","    \n","    return train_dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8t9CDnWR8Nb","colab_type":"code","colab":{}},"source":["def create_aug_dataset(train_folder, augmentation=1):\n","    if augmentation == 0:\n","        aug_dataset = None\n","\n","    elif augmentation == 1:\n","        aug_dataset = HotdogOrNotDataset(train_folder, \n","                              transform=transforms.Compose([\n","                                  transforms.Resize((224, 224)),\n","                                  transforms.ColorJitter(hue=.20, saturation=.20),\n","                                  transforms.RandomHorizontalFlip(),\n","                                  transforms.RandomVerticalFlip(),\n","                                  transforms.RandomRotation(50, resample=Image.BILINEAR),\n","                                  transforms.ToTensor(),\n","                                  transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                        std=[0.229, 0.224, 0.225])                         \n","                              ])\n","                              )\n","        \n","    elif augmentation == 2:\n","        aug_dataset = HotdogOrNotDataset(train_folder, \n","                              transform=transforms.Compose([\n","                                  transforms.Resize((224, 224)),\n","                                  transforms.ColorJitter(hue=.20, saturation=.20),\n","                                  transforms.RandomHorizontalFlip(),\n","                                  transforms.RandomPerspective(),\n","                                  transforms.RandomRotation(50, resample=Image.BILINEAR),\n","                                  transforms.RandomResizedCrop((224, 224), scale=(0.75, 0.95), ratio=(0.75, 1.25)),\n","                                  transforms.ToTensor(),\n","                                  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                         \n","                              ])\n","                              )\n","\n","    return aug_dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mc8iqPqsps9N","colab_type":"code","colab":{}},"source":["def get_model(requires_grad=True):\n","    model = models.resnet18(pretrained=True);\n","\n","    for param in model.parameters():\n","        param.requires_grad = requires_grad\n","\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 2)\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDT1CtxqvOoQ","colab_type":"code","colab":{}},"source":["def get_train_loader(train_dataset, aug_datasets, batch_size = 64):\n","    train_data_size = len(train_dataset)\n","    validation_fraction = .2\n","    val_split = int(np.floor((validation_fraction) * train_data_size))\n","    indices = list(range(train_data_size))\n","    np.random.shuffle(indices)\n","    val_indices, train_indices = indices[:val_split], indices[val_split:]\n","    val_sampler = SubsetRandomSampler(val_indices)\n","    val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler)\n","    \n","    if len(aug_datasets) > 0:\n","        # use only indexes from train dataset\n","        aug_indices = []\n","        step = len(train_dataset)\n","        for d in range(len(aug_datasets)):\n","            idx = [i + step * (d + 1) for i in train_indices]\n","            aug_indices = aug_indices + idx\n","            train_dataset += aug_datasets[d]\n","\n","        train_sampler = SubsetRandomSampler(train_indices + aug_indices)\n","        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n","    else:\n","        train_sampler = SubsetRandomSampler(train_indices)\n","        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n","\n","    return train_loader, val_loader, val_indices"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iY_HAYjd2h1I","colab_type":"code","colab":{}},"source":["def get_optimizer(model, optimizer='sgd'):\n","    lr = 0.001\n","    lr_list = [lr * (0.5 ** i) for i in range(6)]\n","\n","    if optimizer == 'adam':\n","        optimizer = optim.Adam([\n","                  {'params': model.conv1.parameters(),  'lr': lr_list[5]},\n","                  {'params': model.layer1.parameters(), 'lr': lr_list[4]},\n","                  {'params': model.layer2.parameters(), 'lr': lr_list[3]},\n","                  {'params': model.layer3.parameters(), 'lr': lr_list[2]},\n","                  {'params': model.layer4.parameters(), 'lr': lr_list[1]},\n","                  {'params': model.fc.parameters(), 'lr': lr_list[0]}\n","              ])\n","    else:\n","      optimizer = optim.SGD([\n","                  {'params': model.conv1.parameters(),  'lr': lr_list[5]},\n","                  {'params': model.layer1.parameters(), 'lr': lr_list[4]},\n","                  {'params': model.layer2.parameters(), 'lr': lr_list[3]},\n","                  {'params': model.layer3.parameters(), 'lr': lr_list[2]},\n","                  {'params': model.layer4.parameters(), 'lr': lr_list[1]},\n","                  {'params': model.fc.parameters(), 'lr': lr_list[0]}\n","              ], momentum=0.9)\n","      \n","    return optimizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFSQ4v7LvAdm","colab_type":"code","colab":{}},"source":["def train_frame(device, train_folder, batch_size=64, epoch=5, augmentation=0, opt='sgd', requires_grad=True, step_size=1, gamma=1):\n","    # create data\n","    train_dataset = create_train_dataset(train_folder)\n","    \n","    aug_list = []\n","    if augmentation:\n","        for i in range(augmentation):\n","            aug_list.append(create_aug_dataset(train_folder, i + 1))\n","\n","    # create data loaders\n","    train_loader, val_loader, val_indices = get_train_loader(train_dataset, aug_list, batch_size)\n","    # create model\n","    model = get_model(requires_grad)\n","    # send to device\n","    model.to(device);\n","    \n","    \n","    # create optimizer\n","    optimizer = get_optimizer(model, opt)\n","    # create loss-func\n","    loss = nn.CrossEntropyLoss()\n","    # start train\n","    best_model = train_model(model, train_loader, val_loader, train_dataset, val_indices, loss, optimizer, epoch, step_size, gamma)\n","    \n","    return best_model, train_dataset, val_indices"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tttXsvWkJZwo","colab_type":"code","colab":{}},"source":["def evaluate_model(model, train_dataset, indices):\n","    predictions = []\n","    ground_truth = []\n","    \n","    model.eval() # Evaluation mode\n","\n","    for i in indices:\n","        x, y, _ = train_dataset[i]\n","\n","        x = x.unsqueeze(0)\n","\n","        x_gpu = x.to(device)\n","\n","        predictions.append((torch.argmax(model(x_gpu), dim = 1)).cpu().data.numpy()[0])\n","        ground_truth.append(y)\n","    \n","    return predictions, ground_truth"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iO1yZE5oJDJi","colab_type":"code","colab":{}},"source":["def binary_classification_metrics(predictions, gt):\n","    fn = 0\n","    fp = 0\n","    tp = 0\n","    tn = 0\n","    for i in range(len(predictions)):\n","        # FN\n","        if (predictions[i] == 0) & (gt[i] == 1):\n","            fn += 1\n","        # FP\n","        elif (predictions[i] == 1) & (gt[i] == 0):\n","            fp += 1\n","        # TP\n","        elif (predictions[i] == 1) & (gt[i] == 1):\n","            tp += 1\n","        # TN\n","        else:\n","            tn +=1\n","\n","    precision = tp / (tp + fp)\n","\n","    recall = tp / (tp + fn)\n","    f1 = 2 * precision * recall / (precision + recall)\n","\n","    return precision, recall, f1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1LhaxgAVnxat","colab_type":"code","outputId":"310fb842-ce0b-4368-9fda-42db8613d3f6","executionInfo":{"status":"ok","timestamp":1590001515849,"user_tz":-180,"elapsed":1703501,"user":{"displayName":"Константин Шитьков","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCkCq5x25vNYZBSH3vcpBiuv_VP9JI0RltsyLT-g=s64","userId":"04248095687395188930"}},"colab":{"base_uri":"https://localhost:8080/","height":545}},"source":["np.random.seed(42)\n","batch_size = 64\n","epoch = 10\n","augmentation = 2\n","# opt = 'adam'\n","opt = 'sgd'\n","requires_grad = True\n","step_size = 1\n","gamma = 0.8\n","\n","model, train_dataset, val_indices = train_frame(device,\n","                                                train_folder,\n","                                                batch_size,\n","                                                epoch,\n","                                                augmentation,\n","                                                opt,\n","                                                requires_grad,\n","                                                step_size,\n","                                                gamma)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 0\n","Average loss: 0.298940, Train accuracy: 0.868314, Val accuracy: 0.948913\n","F1: 0.915, P: 0.910, R: 0.920\n","Epoch: 1\n","Average loss: 0.197225, Train accuracy: 0.921350, Val accuracy: 0.955435\n","F1: 0.922, P: 0.957, R: 0.891\n","Epoch: 2\n","Average loss: 0.186675, Train accuracy: 0.923794, Val accuracy: 0.957609\n","F1: 0.928, P: 0.943, R: 0.912\n","Epoch: 3\n","Average loss: 0.166773, Train accuracy: 0.936012, Val accuracy: 0.956522\n","F1: 0.925, P: 0.947, R: 0.905\n","Epoch: 4\n","Average loss: 0.160000, Train accuracy: 0.937008, Val accuracy: 0.959783\n","F1: 0.932, P: 0.941, R: 0.923\n","Epoch: 5\n","Average loss: 0.145441, Train accuracy: 0.944248, Val accuracy: 0.960870\n","F1: 0.934, P: 0.944, R: 0.923\n","Epoch: 6\n","Average loss: 0.145449, Train accuracy: 0.942800, Val accuracy: 0.959783\n","F1: 0.932, P: 0.937, R: 0.927\n","Epoch: 7\n","Average loss: 0.140928, Train accuracy: 0.945968, Val accuracy: 0.960870\n","F1: 0.935, P: 0.925, R: 0.945\n","Epoch: 8\n","Average loss: 0.136157, Train accuracy: 0.947778, Val accuracy: 0.961957\n","F1: 0.936, P: 0.944, R: 0.927\n","Epoch: 9\n","Average loss: 0.139994, Train accuracy: 0.945425, Val accuracy: 0.958696\n","F1: 0.930, P: 0.937, R: 0.923\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"orsKNlrsLhQL","colab_type":"code","outputId":"aa58de65-7c47-4b49-e9ef-354a6d84b09b","executionInfo":{"status":"ok","timestamp":1590001530919,"user_tz":-180,"elapsed":1718436,"user":{"displayName":"Константин Шитьков","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCkCq5x25vNYZBSH3vcpBiuv_VP9JI0RltsyLT-g=s64","userId":"04248095687395188930"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# Цель - довести F1 score на validation set до значения > 0.93\n","\n","predictions, gt = evaluate_model(model, train_dataset, val_indices)\n","\n","precision, recall, f1 = binary_classification_metrics(predictions, gt)\n","\n","print(\"F1: %4.3f, P: %4.3f, R: %4.3f\" % (f1, precision, recall))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["F1: 0.930, P: 0.937, R: 0.923\n"],"name":"stdout"}]}]}